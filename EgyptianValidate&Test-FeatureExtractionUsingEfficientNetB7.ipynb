{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OHdvAf42rNq",
        "outputId": "941fc01f-79d8-45ce-9e3c-eff2f1b7d45d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C9c4WYhoEXY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS9knaKyoSsi"
      },
      "outputs": [],
      "source": [
        "validation_video_path = '/content/drive/MyDrive/Egy_data/Validate/'\n",
        "test_video_path = '/content/drive/MyDrive/Egy_data/Test/'\n",
        "validate_nparray_path = '/content/drive/MyDrive/Egy_data/validate_nparray/'\n",
        "test_nparray_path = '/content/drive/MyDrive/Egy_data/test_nparray/'\n",
        "saved_nparray_validate_path = '/content/drive/MyDrive/Egy_data/validate_nparray/data/'\n",
        "saved_nparray_test_path = '/content/drive/MyDrive/Egy_data/test_nparray/data/'\n",
        "\n",
        "img_height , img_width = 600, 600  # dimension of each frame in video\n",
        "seq_len = 40 #the number of images we pass as one sequence (only 70 frames per video) -more frames/ better results/ computationally expensive\n",
        "\n",
        "classes = [0, 1, 2, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAhop77-jnlk",
        "outputId": "f8b68a0d-f632-479e-891b-5f0e65ac830b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"conv_base\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 600, 600, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb7 (Functional)  (None, 2560)             64097687  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,097,687\n",
            "Trainable params: 63,786,960\n",
            "Non-trainable params: 310,727\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def conv_base():\n",
        "    feature_extractor =  tensorflow.keras.applications.EfficientNetB7(input_shape=(img_height,img_width,3),\n",
        "                              include_top=False, weights='imagenet',pooling=\"avg\")\n",
        "\n",
        "    preprocess_input = tensorflow.keras.applications.efficientnet.preprocess_input\n",
        "    inputs = tensorflow.keras.Input((img_height, img_width, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return tensorflow.keras.Model(inputs, outputs, name=\"conv_base\")\n",
        "\n",
        "conv_base = conv_base()\n",
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsfHOVMzIL52"
      },
      "outputs": [],
      "source": [
        "part1=0\n",
        "part2=40\n",
        "part3=80\n",
        "part4=120\n",
        "part5=160\n",
        "part6=200\n",
        "part7=240\n",
        "\n",
        "currentPart = -1\n",
        "def frames_extraction(video_path):\n",
        "\n",
        "    frames_list = []\n",
        "\n",
        "    #creating an object by capturing the given video\n",
        "    #This object can be used to read frames from the captured video\n",
        "    vidObj = cv2.VideoCapture(video_path)\n",
        "\n",
        "    #Counter variable - will be incrementing upto the seq_len\n",
        "    seqCount = 1\n",
        "    #skipCount = 2\n",
        "    defect = 0\n",
        "    successCount = 0\n",
        "    start = 0\n",
        "\n",
        "    #The count variable ensures that the number of extracted frames should be equal to the seq_len\n",
        "    while seqCount <= 40:\n",
        "\n",
        "        #Reading one frame at a time from the video, it returns status (success) and the actual frame (image)\n",
        "        success, image = vidObj.read()\n",
        "        #print(success)\n",
        "        #If it is not able to read the frame properly then success = 0, and code will jump to else part\n",
        "        #if success and skipCount == 0:\n",
        "        if success and start>currentPart:\n",
        "            image = cv2.resize(image, (img_height, img_width))\n",
        "            frames_list.append(image)\n",
        "            seqCount += 1\n",
        "            #skipCount = 2\n",
        "            successCount += 1\n",
        "\n",
        "\n",
        "        elif success and start<=currentPart:\n",
        "            start +=1\n",
        "        #elif skipCount > 0:\n",
        "        #  skipCount -= 1\n",
        "\n",
        "        elif (defect + seqCount) >=300:\n",
        "          break\n",
        "\n",
        "        else:\n",
        "            '''Defect frame will not be added to list of frames and if number of extracted frames is less than the seq_len, video will be rejected, in next section'''\n",
        "            defect += 1\n",
        "            print(\"Defected frame at \", defect, \" \", video_path)\n",
        "\n",
        "    print(start)\n",
        "    print(\"Defected\", defect)\n",
        "    print(\"successCount\", successCount)\n",
        "    frames = np.asarray(frames_list)\n",
        "    vidObj.release()\n",
        "    return frames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMNiAhNnoYna"
      },
      "outputs": [],
      "source": [
        "def create_Data(batch_dir):\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    classes_list = os.listdir(batch_dir)\n",
        "    print(classes_list)\n",
        "\n",
        "    for c in classes_list:\n",
        "        print(c)\n",
        "        # creating the list of videos for the current class\n",
        "        files_list = os.listdir(os.path.join(batch_dir, c))\n",
        "        # weâ€™ll pass videos one by one for frames extraction\n",
        "        for f in files_list:\n",
        "            #extracting the frames from the given video\n",
        "            video_path = (os.path.join(os.path.join(batch_dir, c), f))\n",
        "            #print(video_path)\n",
        "            frames = frames_extraction(video_path)\n",
        "            # Check whether the number of frames is equal to the seq_len, if yes -> process, otherwise reject the current video\n",
        "            if len(frames) == seq_len:\n",
        "                print(np.asarray(frames).shape)\n",
        "                #appending the sequence of frames to the input list X\n",
        "                X.append(conv_base.predict(frames))\n",
        "                #X.append(frames)\n",
        "                #we are creating one hot encoding for target variable\n",
        "                #create the list y of length number of classes, where each element is 0\n",
        "                y = [0]*len(classes)\n",
        "                #We find the index of current class c in the classes list and making corresponding element 1 in y\n",
        "                y[classes.index(int(c))] = 1\n",
        "                #Now we append the list y into Y\n",
        "                Y.append(y)\n",
        "\n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validate all parts\n",
        "parts = [\"part1\", \"part2\", \"part3\", \"part4\", \"part5\", \"part6\", \"part7\"]\n",
        "parts_value = [part1, part2, part3, part4, part5, part6, part7]\n",
        "batches_list = os.listdir(validation_video_path)\n",
        "print(\"batches_list\", batches_list)\n",
        "saved_batches = os.listdir(saved_nparray_validate_path) #no need for this if we have good reources\n",
        "print(\"saved_batches\", saved_batches)\n",
        "counter = 0\n",
        "#for i in range(7):\n",
        "for i in range(6):\n",
        "        if parts[i]+\".npy\" in saved_batches: #no need for the if we have no resources\n",
        "          skippedBatch = np.load(os.path.join(validate_nparray_path, \"data\" , parts[i]+\".npy\"))\n",
        "          print(parts[i], \"skipped\", skippedBatch.shape)\n",
        "          continue\n",
        "        currentPart = parts_value[i]\n",
        "        print(\"currentPart \", parts[i])\n",
        "        x_batch, y_batch = create_Data(validation_video_path)\n",
        "        x_batch = np.asarray(x_batch)\n",
        "        y_batch = np.asarray(y_batch)\n",
        "        np.save(os.path.join(validate_nparray_path, \"data\", parts[i]), x_batch)\n",
        "        np.save(os.path.join(validate_nparray_path, \"label\", parts[i]), y_batch)\n",
        "\n",
        "        counter += 1\n",
        "        print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPsodiwQCNST",
        "outputId": "34e52f5a-14b2-40b3-d1fe-1ed72f17c6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batches_list ['2', '3', '0', '1']\n",
            "saved_batches ['part1.npy', 'part2.npy', 'part3.npy', 'part4.npy', 'part5.npy', 'part6.npy', '.ipynb_checkpoints']\n",
            "part1 skipped (350, 40, 2560)\n",
            "part2 skipped (350, 40, 2560)\n",
            "part3 skipped (350, 40, 2560)\n",
            "part4 skipped (349, 40, 2560)\n",
            "part5 skipped (349, 40, 2560)\n",
            "part6 skipped (349, 40, 2560)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "validation_data = np.load(\"/content/drive/MyDrive/Egy_data/validate_nparray/data/part6.npy\")\n",
        "validation_label = np.load(\"/content/drive/MyDrive/Egy_data/validate_nparray/label/part6.npy\")\n",
        "print(validation_data.shape)\n",
        "print(validation_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JczsNjQG_sRR",
        "outputId": "8c6cf6ef-b447-4c0a-bc42-f9985ef7342f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(349, 40, 2560)\n",
            "(349, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test all parts\n",
        "parts = [\"part1\", \"part2\", \"part3\", \"part4\", \"part5\", \"part6\", \"part7\"]\n",
        "parts_value = [part1, part2, part3, part4, part5, part6, part7]\n",
        "batches_list = os.listdir(test_video_path)\n",
        "print(\"batches_list\", batches_list)\n",
        "saved_batches = os.listdir(saved_nparray_test_path) #no need for this if we have good reources\n",
        "print(\"saved_batches\", saved_batches)\n",
        "counter = 0\n",
        "for i in range(6):\n",
        "        if parts[i]+\".npy\" in saved_batches: #no need for the if we have no resources\n",
        "          skippedBatch = np.load(os.path.join(test_nparray_path, \"data\" , parts[i]+\".npy\"))\n",
        "          print(parts[i], \"skipped\", skippedBatch.shape)\n",
        "          continue\n",
        "        currentPart = parts_value[i]\n",
        "        print(\"currentPart \", parts[i])\n",
        "        x_batch, y_batch = create_Data(test_video_path)\n",
        "        x_batch = np.asarray(x_batch)\n",
        "        y_batch = np.asarray(y_batch)\n",
        "        np.save(os.path.join(test_nparray_path, \"data\", parts[i]), x_batch)\n",
        "        np.save(os.path.join(test_nparray_path, \"label\", parts[i]), y_batch)\n",
        "\n",
        "        counter += 1\n",
        "        print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6Ha9OiRc7lp",
        "outputId": "346b5a86-f220-4dfa-fda0-e91028fafb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batches_list ['2', '1', '0', '3']\n",
            "saved_batches ['part1.npy', 'part2.npy', 'part3.npy', 'part4.npy', 'part5.npy', 'part6.npy', '.ipynb_checkpoints']\n",
            "part1 skipped (350, 40, 2560)\n",
            "part2 skipped (346, 40, 2560)\n",
            "part3 skipped (346, 40, 2560)\n",
            "part4 skipped (345, 40, 2560)\n",
            "part5 skipped (345, 40, 2560)\n",
            "part6 skipped (345, 40, 2560)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOIPQcPsofj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53478080-ff57-4c9b-b863-8ab6b7c71f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(345, 40, 2560)\n",
            "(345, 40, 2560)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_data = np.load(\"/content/drive/MyDrive/Egy_data/test_nparray/data/part6.npy\")\n",
        "test_label = np.load(\"/content/drive/MyDrive/Egy_data/test_nparray/data/part6.npy\")\n",
        "print(test_data.shape)\n",
        "print(test_label.shape)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}